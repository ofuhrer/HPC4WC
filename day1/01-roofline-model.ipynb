{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Roofline Model and Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "from IPython.display import YouTubeVideo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## von Neumann Architecture\n",
    "\n",
    "In 1945, [ENIAC](https://en.wikipedia.org/wiki/ENIAC), the first electronic general purpose digital computer was put to work. John von Neumann, a mathematician working on the hydrogen bomb at Los Alamos National Laboratory in the US, became aware of the ENIAC computer and realized its potential to speedup the computations actual people were doing. He subsequently became deeply involved in the design of such computers and published an architecture still in use in modern computers which became known as the [von Neumann architecture](https://en.wikipedia.org/wiki/Von_Neumann_architecture).\n",
    "\n",
    "![von Neumann architecture](img/von_neumann_architecture.png)\n",
    "\n",
    "The von Neumann architecture is based on the stored-program computer concept, where the instructions to be executed as well as the data are stored in a <font color=\"orange\">*memory unit*</font> which typically consists of RAM. The memory unit is connected to the <font color=\"blue\">*central processing unit (CPU)*</font> via a connection called a <font color=\"green\">*bus*</font>. The instructions need to be transferred to the *control unit* in the CPU in order to be executed. The control unit of each CPU understands a certain set of instructions. Load and store instructions are responsible for transferring data from and to the memory. The *arithmetic / logic unit* is responsible for operations on data, such as performing addition or multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Now it's your turn...</b><br>\n",
    "<b>1.</b> Think of some advantages / disadvantages of this computer architecture.<br>\n",
    "<b>2.</b> Another popular computer architecture mostly used in microcontrollers and signal processing is the Harvard architecture. Look it up and figure out how it is different.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) TODO\n",
    "# Advantages\n",
    "# - ...\n",
    "# Disadvantages\n",
    "# - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) TODO\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clock Rate\n",
    "\n",
    "The CPU contains a [clock](https://en.wikipedia.org/wiki/Clock_rate) which is responsible for synchronizing the operations of its components (see figure above). Some components (e.g. memory) may have its own clock (see figure above). For example, in a simple CPU, an instruction is executed every clock cycle. In modern CPUs the situation is slightly more complex since engineers have found ways to design the chip in such a manner that it may be possible to execute multiple instructions in one clock cycle using techniques such as instruction pipelining or out-of-order execution. The metric measuring the number of *clock cycles per instruction (CPI)* is often reported when investigating the performance of a program.\n",
    "\n",
    "The clock signal transitions from 0 to 1 and back to 0 and so on with a given frequency, the *clock frequency* or *clock rate*. The clock rate is measured in hertz (Hz). Common clock rates of modern CPUs are in the range of gigahertz (GHz)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Now it's your turn...</b><br>\n",
    "<b>3.</b> Find out the clock frequency of the Intel Haswell CPUs of Piz Daint by inspecting the <tt>/proc/cpuinfo</tt> file (see below).<br>\n",
    "<b>4.</b> Modern CPUs have multiple cores, which each contain a control unit and an ALU. Find out the number of cores on the CPUs of Piz Daint. Check your answer on the <a href=\"https://www.cscs.ch/computers/piz-daint/\">CSCS website</a> looking at data for the Piz Daint XC50 compute nodes.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clock_frequency =  # TODO\n",
    "number_of_cores =  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLOP/s\n",
    "\n",
    "In high-performance computing, a common measure of performance is the number of *floating-point operations (FLOP)*, i.e. multiplications, additions, ...) per second. This stems from the fact, that scientific programs such as weather and climate models often involve a large number of floating point operations.\n",
    "\n",
    "![flops](img/flops.png)\n",
    "\n",
    "The [fastest supercomputer](https://en.wikipedia.org/wiki/Fugaku_(supercomputer)) in the world currently achieves an incredible 1.102 Exaflop/s in double precision. (See also [this page](https://kb.iu.edu/d/apeq) for more information.) There is a list keeping track of the fastest supercomputers called the [top500](https://www.top500.org) which is updated bi-anually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('ZaJp6ZYP6Xc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical Peak Performance\n",
    "\n",
    "A processor's theoretical peak performance is a an upper bound for the floating-point performance one can expect from a CPU. It is computed as\n",
    "\n",
    "$$\\mathrm{peak_{FLOPS}} = 2 \\times \\mathrm{cores} \\times f \\times n$$\n",
    "\n",
    "where *cores* is the number of cores on a CPU, $f$ is the clock frequency, and $n$ is the number of floating-point operations the processor can perform per clock cycle. The factor of 2 in front is because most modern processors have an [multiply-accumulate](https://en.wikipedia.org/wiki/Multiplyâ€“accumulate_operation) instruction - also called fused multiply-add - which executes a multiplication and an addition in a single instruction.\n",
    "\n",
    "$$\\mathrm{fmad}(a,b,c) = a + (b \\times c)$$\n",
    "\n",
    "The Intel E5-2690 v3 Haswell processor on Piz Daint have a value of $n=8$, meaning that they can execute 8 double precision floating point operations in a single clock cycle. This is due to so called vector registers and vector instructions. More information about the theoretical peak performance of Intel processors can be found [here](http://www.dolbeau.name/dolbeau/publications/peak.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Now it's your turn...</b><br>\n",
    "<b>5.</b> Compute how many floating point operations each person on Earth would have to do per second in order to achieve 1.102 Exaflop/s. That didn't help, still impossible to imagine! Can you think of a cool way of explaining what 1.102 Exaflop/s means?<br>\n",
    "<b>6.</b> Compute the theoretical peak performance of the Intel E5-2690 v3 Haswell processors you are currently working on. Can you think of some reasons why achieving peak performance is difficult for a real application?<br>\n",
    "<b>7.</b> Take a look at the <tt>logistic_map</tt> method below. Compute the number of FLOP that <tt>logicist_map</tt> method will execute given values of <tt>number_of_iterations</tt>, <tt>number_of_r_values</tt>, and <tt>number_of_x_values</tt> (Hint: ignore the plotting for your calculation).<br>\n",
    "<b>8.</b> Run the Python code to execute and time <tt>logistic_map</tt>. Compute the fraction of theoretical peak performance we have achieved.<br>\n",
    "<b>9.</b> Change the code to no longer plot the result and measure performance once again.<br>\n",
    "<b>10.</b> Did you expect the resulting value? Why?<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flops_per_capita =  # TODO\n",
    "print(\"FLOP/s per person = {}\".format(flops_per_capita))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_performance_in_gflops =  # TODO\n",
    "print(\"peak performance = {} GFLOP/s\".format(peak_performance_in_gflops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) TODO\n",
    "# Reasons why peak performance is hard to achieve in practice?\n",
    "# - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_iterations = 100\n",
    "number_of_r_values = 500\n",
    "number_of_x_values = 500\n",
    "\n",
    "def logistic_map(do_plot=True):\n",
    "    for r in np.linspace(0.1, 4., number_of_r_values):\n",
    "        x = np.linspace(0.01, 0.99, number_of_x_values)\n",
    "        for iter in range(number_of_iterations):\n",
    "            x = r * x * ( 1. - x )\n",
    "        if do_plot:\n",
    "            plt.plot(np.repeat(r, number_of_x_values), x, 'k.', markersize=0.1)\n",
    "\n",
    "# total number of floating-point operations\n",
    "number_of_flop =  # TODO\n",
    "\n",
    "# time the execution\n",
    "tic = timeit.default_timer()\n",
    "logistic_map(do_plot=True)\n",
    "toc = timeit.default_timer()\n",
    "execution_time = toc - tic\n",
    "print(\"execution time = {} s\".format(execution_time))\n",
    "\n",
    "# compute the flop/s\n",
    "performance_in_gflops =  # TODO\n",
    "print(\"performance = {} GFLOP/s\".format(performance_in_gflops))\n",
    "\n",
    "# compute fraction of peak\n",
    "fraction_of_peak_performance =  # TODO\n",
    "print(\"% of peak = {:8.5f}%\".format(fraction_of_peak_performance * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Bandwidth\n",
    "\n",
    "In the von Neumann architecture the memory (RAM) is connected to the CPU via a [bus](https://en.wikipedia.org/wiki/Bus_(computing)), which is a technical term for a connection between two hardware units in a computer. In the picture below of an actual Cray supercomputer the memory (RAM) is on separate hardware components next to the CPU. The electrical wires connecting the memory to the CPU and the communication protocol are collectively referd to as the memory bus. \n",
    "\n",
    "![xc30 node](img/xc30_node.png)\n",
    "\n",
    "[Memory bandwidth](https://en.wikipedia.org/wiki/Memory_bandwidth) is the rate at which data can be transferred between the CPU and memory. The unit used to specify memory bandwidth of modern processors is GB/s (gigabyte/s).\n",
    "\n",
    "## Theoretical Peak Bandwidth\n",
    "\n",
    "Theoretical peak memory bandwidth can be calculated from the clock frequency of the memory bus $f$ (memory clock frequency), the number of channels and the width of the memory bus (number of bits)\n",
    "\n",
    "$$\\mathrm{peak_{BW}} = f_\\mathrm{DDR} \\times \\mathrm{channels} \\times \\mathrm{width}$$\n",
    "\n",
    "The Piz Daint compute nodes use DDR4 memory with a frequency of $2133 MHz$ and has a memory bus with 4 channels each 64 bits wide. See [information by Intel](https://ark.intel.com/content/www/us/en/ark/products/81713/intel-xeon-processor-e5-2690-v3-30m-cache-2-60-ghz.html) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Now it's your turn...</b><br>\n",
    "<b>11.</b> Use the <tt>sys.getsizeof()</tt> method to investigate the number of bytes different numpy data types occupy in memory (byte, float32, float64, int32, int64). The results are slightly larger than expected because Python stores additional information about objects that also occupy some space, but it is safe to round these numbers for large data arrays. Change the <tt>num_elements</tt> to 1 in order to check the fixed overhead of storing data in a numpy array. This is a fixed overhead, since as you increase the number of elements in the data array, the values approach the expected valued, i.e. 4 bytes for a <tt>float32</tt> and 8 bytes for a <tt>float64</tt>.<br>\n",
    "<b>12.</b> Compute the theoretical peak memory bandwidth of the Intel E5-2690 v3 Haswell processors you are currently working on.<br>\n",
    "<b>13.</b> Take a look at the <tt>vector_add</tt> method below. Compute the total number of bytes and GB that have to be loaded from or stored to memory for the <tt>vector_add</tt> method.<br>\n",
    "<b>14.</b> Run the vector addition and compute the achieved memory bandwidth in GB/s and the % of the theorical peak memory bandwidth. You will have to add timers around the <tt>vector_add(a, b, c)</tt> invocation (see above). Is the result what you expected?<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = [np.byte, np.float32, np.float64, np.int32, np.int64]\n",
    "num_elements = 1024 * 1024\n",
    "for data_type in data_types:\n",
    "    x = np.empty((num_elements), dtype=data_type)\n",
    "    print('{} has a size of {:.4f} bytes'.format(data_type.__name__, sys.getsizeof(x) / num_elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_bandwidth_in_gbs =  # TODO\n",
    "print(\"peak memory bandwidth = {} GB/s\".format(peak_bandwidth_in_gbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_add(a, b, c):\n",
    "    c[:] = a[:] + b[:]\n",
    "\n",
    "num_elements = 128 * 1024 * 1024\n",
    "a = np.random.rand( num_elements )\n",
    "b = np.random.rand( num_elements )\n",
    "c = np.empty( num_elements, dtype=np.float64 )\n",
    "\n",
    "# compute the number of bytes loaded/stored from/to memory\n",
    "number_of_bytes =  # TODO\n",
    "number_of_gbytes =  # TODO\n",
    "print(\"memory transferred = {} GB\".format(number_of_gbytes))\n",
    "\n",
    "# time the execution\n",
    "tic = timeit.default_timer()\n",
    "vector_add(a, b, c)\n",
    "toc = timeit.default_timer()\n",
    "execution_time = toc - tic\n",
    "print(\"execution time = {:8.5f} s\".format(execution_time))\n",
    "\n",
    "# memory bandwidth\n",
    "memory_bandwidth_in_gbs =  # TODO\n",
    "print(\"memory bandwidth = {:8.5f} GB/s\".format(memory_bandwidth_in_gbs))\n",
    "\n",
    "# compute fraction of peak\n",
    "fraction_of_peak_bandwidth =  # TODO\n",
    "print(\"% of peak = {:8.5f}%\".format(fraction_of_peak_bandwidth * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>15. (Bonus)</b> Implement the above vector addition in a low-level programming language (e.g. C/C++ or Fortran) or another scripting language (e.g. Julia) and compare the results.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithmetic intensity\n",
    "\n",
    "Weather and climate models need to perform operations (e.g. integrating partial differential equations) on data (e.g. prognostic variables such as density, pressure or wind stored on a mesh). The *arithmetic intensity* or *operational intensity* $I$ is a measure that relates the amount of work $W$ (floating-point operations) to the amount of data $Q$ (bytes) that needs to be transferred to the CPU.\n",
    "\n",
    "$$I = \\frac{W}{Q} \\,\\, [\\mathrm{flop}/\\mathrm{byte}]$$\n",
    "\n",
    "Often, the artihmetic intensiy is expressed as a function of input size $n$, namely $I(n) = W(n)/Q(n)$ and approximated in the limit of large $n$.\n",
    "\n",
    "Computer programs with low arithmetic intensity $I << 1$ are called *memory bound*. Programs with high arithmetic intensity $I >> 1$ are called *compute bound*. The transition point from compute bound to memory bound is hardware dependent and depends on the achievable FLOPs and memory bandwidth values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Now it's your turn...</b><br>\n",
    "<b>16.</b> Assume that the theoretical peak values of FLOPS and memory bandwidth are actually achievable on the Intel E5-2690 v3 processor. At what arithmetic intensity $I_\\mathrm{transition}$ would a computer program make optimal use of the ALU and memory bus? If you were to load a single <tt>float32</tt> from memory, do some computation, and then store the result back to memory, how many flops would you have to do in order not to stall the ALU?<br>\n",
    "<b>17.</b> Consider the one-dimensional heat equation in a domain $x \\in [0, L]$ with periodic boundary conditions\n",
    "    \n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\\\[0.5ex]\n",
    "\\frac{\\partial T}{\\partial t} && = && \\alpha \\frac{\\partial^2 T}{\\partial^2 x}\\\\[1.5ex]\n",
    "T(x,0) && = && \\cos \\left( \\frac{2 \\pi}{L} x \\right)\\\\[1.5ex]\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "    \n",
    "where $T = T(x,t)$ is the temperature and $\\alpha > 0\\,m^2/s$ is the diffusion coefficient. Discretize the spatial dimension using 2nd-order central differences and constant $\\Delta x = L / m$ where $m$ is the number of gridpoints. Discretize in time using a simple Euler forward scheme with $\\Delta t$. Now compute the operational intensity $I(m)$ for the scheme assuming the computation is done in double precision (<tt>float64</tt>).<br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_arithmetic_intensity =  # TODO\n",
    "print(\"I_transition = {} flop/byte\".format(transition_arithmetic_intensity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flop_per_loadstore =  # TODO\n",
    "print(\"{} floating-point operations for a load/store of a float32\".format(flop_per_loadstore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Discretization of one-dimensional heat equation as follows...\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\\\[0.5ex]\n",
    "x_i = i \\, \\Delta x \\,\\,\\,\\,\\,\\, t^n = n \\, \\Delta t \\\\[1.5ex]\n",
    "T^n_i = T(x_i, t^n) \\\\[1.5ex]\n",
    "\\partial_t T^n_i \\approx \\left( T^{n+1}_i - T^n_i \\right) / \\Delta t\\\\[1.5ex]\n",
    "\\partial_x^2 T^n_i \\approx \\left( T^n_{i-1} - 2 T^n_i + T^n_{i+1} \\right) / \\Delta x^2\\\\[1.5ex]\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution (TODO): \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>17. (Bonus)</b> Determine the asymptotic value of the arithmetic intensity $I(n)$ for large $n$ for the following vector/matrix operations in double precision (<tt>float64</tt>).\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "y && = && \\alpha x + y \\,\\,\\,\\,  && \\alpha \\in \\mathbb{R}; \\,\\, x, y \\in \\mathbb{R}^n \\\\[1.5ex]\n",
    "y && = && \\mathrm{A} x + y \\,\\,\\,\\,  && x, y \\in \\mathbb{R}^n; \\,\\, \\mathrm{A} \\in \\mathbb{R}^{n \\times n} \\\\[1.5ex]\n",
    "C && = && \\mathrm{A} \\mathrm{B} + \\mathrm{C} \\,\\,\\,\\,  && \\mathrm{A}, \\mathrm{B}, \\mathrm{C} \\in \\mathbb{R}^{n \\times n} \\\\[1.5ex]\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "    \n",
    "Assume that the values of $\\mathrm{A}$, $\\mathrm{B}$, and $\\mathrm{C}$ only have to be transferred from memory once. If the result is a function of the vector and matrix size $n$ then compute the arithmetic intensity of asymptotically large $n$.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus (skip at first)\n",
    "\n",
    "def scalar_add(a,x,y):\n",
    "    # TODO: implement daxpy\n",
    "    pass\n",
    "W_daxpy =  # TODO\n",
    "Q_daxpy =  # TODO\n",
    "I_daxpy =  # TODO\n",
    "\n",
    "def matrix_vector_multiply(A,x,y):\n",
    "    # TODO: implement dgemv\n",
    "    pass\n",
    "W_dgemv =  # TODO\n",
    "Q_dgemv =  # TODO\n",
    "I_dgemv =  # TODO\n",
    "\n",
    "def matrix_multiply(A, B, C):\n",
    "    # TODO: implement dgemm\n",
    "    pass\n",
    "W_dgemm =  # TODO\n",
    "Q_dgemm =  # TODO\n",
    "I_dgemm =  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roofline model\n",
    "\n",
    "The Roofline model ([Williams et al. 2009](https://www.osti.gov/servlets/purl/963540)) is a simple and intuitive model that can give insight into how to improve the performance of a computer program or an individual kernel inside such a program. It shows the performance of the kernel in the context of hardware limitations (memory bandwidth, peak performance) and can help guide optimizations. The underlying assumption is that memory accesses or floating point operations are the dominant factors determining the performance of a program.\n",
    "\n",
    "If a kernel is compute bound (limited by throughput of floating point operations), optimizations should target techniques such as vectorization, pipelining, better instruction mix, etc. If a kernel is memory bound (limited by reading and writing of data from and to memory), optimizations should aim at a reduction of memory transfers. The roofline model immediately shows how close to theoretical peak performance (the roofline) a kernel is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operational_intensity = 2 ** np.linspace(-4, 10, 100)\n",
    "roofline = np.minimum( operational_intensity * peak_bandwidth_in_gbs, peak_performance_in_gflops )\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.set_xscale(\"log\", base=2)\n",
    "ax.set_yscale(\"log\", base=2)\n",
    "xlim = ( np.min(operational_intensity), np.max(operational_intensity) )\n",
    "ylim = ( 0.25 * np.min(roofline), 4 * peak_performance_in_gflops )\n",
    "ax.plot( operational_intensity, roofline, 'k-');\n",
    "ax.plot( operational_intensity, np.repeat(peak_performance_in_gflops, 100), 'k', linestyle=\"dashed\" );\n",
    "ax.plot( operational_intensity, operational_intensity * peak_bandwidth_in_gbs, 'k', linestyle=\"dashed\" );\n",
    "ax.text( 2.1, 19, 'memory\\nbound', color='red', fontsize=12)\n",
    "ax.plot( [8,8], [ylim[0], peak_performance_in_gflops ], 'r', linewidth=4, linestyle=\"dashed\")\n",
    "plt.xlabel(\"arithmetic intensity [flop/byte]\");\n",
    "plt.ylabel(\"performance [gflop/s]\");\n",
    "plt.xlim( xlim )\n",
    "plt.ylim( ylim );\n",
    "plt.grid(True, which=\"both\", ls='--');\n",
    "ax.text( 12.8, 19, 'compute\\nbound', color='red', fontsize=12)\n",
    "\n",
    "# TODO: add point for stencil_2d.F90 at nx=128 ny=128 nz=64 num_iter=1024\n",
    "#ax.plot( stencil2d_intensity, stencil2d_gflops, 'g.')\n",
    "#ax.text( 1.1*stencil2d_intensity, stencil2d_gflops, \"stencil2d\", color='green')\n",
    "\n",
    "# TODO (Bonus): add point for matrix-matrix multiplication\n",
    "#ax.plot( matmul_intensity, matmul_gflops, 'b.')\n",
    "#ax.text( 1.1*matmul_intensity, matmul_gflops, \"matmul\", color='blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Now it's your turn...</b><br>\n",
    "<b>18.</b> Add a data point for the <tt>stencil2d-counter.F90</tt> program (see next Jupyter notebook and uncomment corresponding section in plot above). Is the stencil program compute bound or memory bound? What could you do to improve the performance of the program?<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stencil_2d.F90 with nx=128 ny=128 nz=64 num_iter=1024\n",
    "stencil2d_gflop_counter =  # TODO\n",
    "stencil2d_gb_counter =  # TODO\n",
    "stencil2d_runtime =  # TODO\n",
    "stencil2d_intensity =  # TODO\n",
    "stencil2d_gflops =  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Now it's your turn...</b><br>\n",
    "<b>19 (Bonus).</b> Add a data point for the matrix-matrix multiplication example below (uncomment corresponding section in plot above). What will happen if you decrease the matrix size $n$? Try it out!<br>\n",
    "<b>20 (Bonus).</b> There are a lot of resources to be found about memory bandwidth, arithmetic intensity and the roofline model. Spend some time researching more background information, for example for example <a href=\"http://www.dam.brown.edu/people/lgrinb/APMA2821/Lectures_2015/APMA2821H-L_roof_line_model.pdf\">here</a>.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8 * 1024\n",
    "A = np.random.rand(n, n)\n",
    "B = np.random.rand(n, n)\n",
    "\n",
    "tic = timeit.default_timer()\n",
    "C = A.dot(B)\n",
    "toc = timeit.default_timer()\n",
    "execution_time = toc - tic\n",
    "\n",
    "# approximated for large n\n",
    "matmul_flops =  # TODO\n",
    "matmul_intensity =  # TODO\n",
    "matmul_gflops =  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
