{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Memory Parallelism with OpenMP\n",
    "\n",
    "During this exercise we will parallelize the stencil program from day 1 using OpenMP. The goal is to apply the OpenMP concepts that have been discussed in the lecture. If everything goes well, at the end of this exercise you will have a parallel version of the diffusion operator.\n",
    "\n",
    "So let's start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Baseline\n",
    "\n",
    "In the first step we will see how fast our code performs and what the straightforward insertion of compiler directives (pragmas) can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by compiling the Fortran stencil2d base code (this is the code with inlining your have worked on previusly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "make clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load daint-gpu\n",
    "module switch PrgEnv-gnu PrgEnv-cray\n",
    "module load perftools-lite\n",
    "\n",
    "make clean\n",
    "make VERSION=base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This created **two** executables. `stencil2d-base.x+orig` is the executable which is simply compiled and not instrumented by perftools-lite for performance profiling. `stencil2d-base.x` is an executable that has been instrumented for performance profiling and will generate a performance report at the end of execution.\n",
    "\n",
    "Let's run the version without performance profiling to get a baseline runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "srun -n 1 ./stencil2d-base.x+orig --nx 128 --ny 128 --nz 64 --num_iter 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note of the runtime (the last value in the `data` array). This is our sequential baseline. It should be on the order of 0.8 s. As reminder, this time is only the time it takes to execute the loop over the iterations where we apply the diffusion stencil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you feel more comfortable with C++, there is also a version available in C++. Future make commands have both versions inside. Comment and uncomment based on your preferred language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load daint-gpu\n",
    "module load perftools-lite\n",
    "\n",
    "CC stencil2d-base.cpp -fopenmp -o stencil2d-base.x -O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "srun -n 1 ./stencil2d-base.x+orig --nx 128 --ny 128 --nz 64 --num_iter 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "As a first step, it is always good to make sure that the code is working correctly before proceeding with any sort of parallelization or optimization. We plot the initial and final step to see that the code still produces the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_field_from_file(filename, num_halo=None):\n",
    "    (rank, nbits, num_halo, nx, ny, nz) = np.fromfile(filename, dtype=np.int32, count=6)\n",
    "    offset=(3 + rank) * 32 // nbits\n",
    "    data = np.fromfile(filename, dtype=np.float32 if nbits == 32 else np.float64, \\\n",
    "                       count=nz * ny * nx + offset)\n",
    "    if rank == 3:\n",
    "        return np.reshape(data[offset:], (nz, ny, nx))\n",
    "    else:\n",
    "        return np.reshape(data[offset:], (ny, nx))\n",
    "\n",
    "def validate_results():\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    in_field = read_field_from_file('in_field.dat')\n",
    "    im1 = axs[0].imshow(in_field[in_field.shape[0] // 2, :, :], origin='lower', vmin=-0.1, vmax=1.1);\n",
    "    fig.colorbar(im1, ax=axs[0]);\n",
    "    axs[0].set_title('Initial condition');\n",
    "\n",
    "    out_field = read_field_from_file('out_field.dat')\n",
    "    im2 = axs[1].imshow(out_field[out_field.shape[0] // 2, :, :], origin='lower', vmin=-0.1, vmax=1.1);\n",
    "    fig.colorbar(im2, ax=axs[1]);\n",
    "    axs[1].set_title('Final result');\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelization of the K-Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use perftools-lite to generate a performance report for the base version. This will be useful to guide our parallelization approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "srun -n 1 ./stencil2d-base.x --nx 128 --ny 128 --nz 64 --num_iter 1024 > report_base.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the performance report in the file `report_base.txt`. Which are the lines which consume most of the runtime (hot loops)? These code regions should be the primary targets for parallelization with OpenMP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Now it's your turn...</b><br>\n",
    "<b>1.</b> Make a copy of the source code and name it <tt>stencil2d-kparallel.F90</tt>. Compile it (see cell below) and run it (see cell after that). For the time being, the runtime should be the same as the base version. Insert the following block of code immediately at program start to print out the number of available threads.<br>\n",
    "<b>Fortran</b><br>\n",
    "<code>!$omp parallel\n",
    "!$omp master\n",
    "!$ write(*,*) '#threads = ', omp_get_num_threads()\n",
    "!$omp end master\n",
    "!$omp end parallel\n",
    "</code>\n",
    "<b>C++</b><br>\n",
    "<code>#pragma omp parallel\n",
    "  {\n",
    "#pragma omp master\n",
    "    { std::cout << \"#threads = \" <<  omp_get_num_threads() << std::endl; }\n",
    "  }\n",
    "</code>\n",
    "Compile and run your code again. How many threads do we have available? Does the number match the number of cores?\n",
    "<br>\n",
    "<b>2.</b> Now use OpenMP to parallelize the <tt>k</tt>-loop. Compile the code again and execute it. Quickly check that the results are still ok (using <tt>validate_results()</tt>, see below)<br>\n",
    "<b>3.</b> What does the plot tell you? What might be the issue?<br>\n",
    "<b>4.</b> Irrespective of the result, how fast is your code relative to the base version? What would you have expected?<br>\n",
    "<b>5.</b> Generate a perftools-lite report and check what changed relative to the base version. What are the places that consume most of the runtime now?<br>\n",
    "<b>6.</b> Rerun for <tt>nz</tt>=1, 24, 25, 48, 64 ,480 and inspect the perftools-lite report for each of these settings. Look at how the relative distribution of runtime changes in table 2. Can you guess what is happening? Why is <tt>nz</tt>=64 not an ideal setting?<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# For Fortran uncomment these lines\n",
    "module load daint-gpu\n",
    "module switch PrgEnv-gnu PrgEnv-cray\n",
    "module load perftools-lite\n",
    "make VERSION=kparallel\n",
    "\n",
    "# For C++ uncomment these lines\n",
    "#module load daint-gpu\n",
    "#module load perftools-lite\n",
    "#CC stencil2d-kparallel.cpp -fopenmp -o stencil2d-kparallel.x -O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "srun -n 1 ./stencil2d-kparallel.x+orig --nx 128 --ny 128 --nz 64 --num_iter 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "srun -n 1 ./stencil2d-kparallel.x --nx 128 --ny 128 --nz 64 --num_iter 1024 > report_kparallel.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Scoping\n",
    "\n",
    "Inside a parallel region, variables can be either *shared* (all threads see the same copy) or *private* (each thread has its own copy). For now, we have not explicitly declared the scope of variables that are being used in the parallel region. If nothing is specified, the compiler assumes per default that all variables are shared. This is dangerous and can lead to very ugly errors. This is the error you've encountered above.\n",
    "\n",
    "Some guidelines you can follow to decide the scope of variables are the following:\n",
    "- Loop indices are private.\n",
    "- Variables that are used (read or written) solely inside the parallel region are private.\n",
    "- Variables that are only being read inside the parallel region are shared.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Now it's your turn...</b><br>\n",
    "<b>7.</b> In order to avoid the default behavior, append the <code>default(none)</code> clause on the line with the <code>!$omp parallel do</code>.Recompile (see below). The compiler will now complain that the scope of several variables has not explictly been specified. For each of these variables, you have to decide whether they are <code>private(var)</code> or <code>shared(var)</code>.<br>\n",
    "<b>8.</b> Once your code compiles, run it and validate that the results are still looking correct.<br>\n",
    "<b>9.</b> Move a single variable (e.g. <tt>nx</tt>) from shared to private, recompile, run and visualize the results. Do you understand what happened?<br>\n",
    "<b>10.</b> Once you are sure that the variable scoping is correct, run one final time and compare the runtime against the previous version and the baseline. Do you understand why we are faster?<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# For Fortran uncomment these lines\n",
    "module load daint-gpu\n",
    "mdule switch PrgEnv-gnu PrgEnv-cray\n",
    "module load perftools-lite\n",
    "make VERSION=kparallel\n",
    "\n",
    "# For C++ uncomment these lines\n",
    "#module load daint-gpu\n",
    "#module load perftools-lite\n",
    "#CC stencil2d-kparallel.cpp -fopenmp -o stencil2d-kparallel.x -O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "srun -n 1 ./stencil2d-kparallel.x+orig --nx 128 --ny 128 --nz 64 --num_iter 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "srun -n 1 ./stencil2d-kparallel.x --nx 128 --ny 128 --nz 64 --num_iter 1024 > report_kparallel.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelization of the J-Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Now it's your turn...</b><br>\n",
    "<b>11.</b> Make a copy of the <tt>stencil2d-kparallel.F90</tt> program and name it <tt>stencil2d-jparallel.F90</tt>. This time use OpenMP to parallelize the <tt>j</tt>-loop. Make sure to remove the <tt>k</tt>-loop parallelization. Compile it and run it. How fast is your code? What would you have expected?<br>\n",
    "<b>12.</b> Again generate a report. What changed? Can you use the report to explain your findings above?<br>\n",
    "    <b>13.</b>  Run you code using just 1 thread (<code>OMP_NUM_THREADS=1</code>). How does the runtime compare against the base version? Run the both versions of the code several times to make sure the result is reproducible. What could be the reason for the difference?<br>\n",
    "<b>13.</b> Is it a good idea to try and parallelize the <tt>i</tt>-loop? Why?<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# For Fortran uncomment these lines\n",
    "module load daint-gpu\n",
    "module switch PrgEnv-gnu PrgEnv-cray\n",
    "module load perftools-lite\n",
    "make VERSION=jparallel\n",
    "\n",
    "# For C++ uncomment these lines\n",
    "#module load daint-gpu\n",
    "#module load perftools-lite\n",
    "#CC stencil2d-jparallel.cpp -fopenmp -o stencil2d-jparallel.x -O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "srun -n 1 ./stencil2d-jparallel.x+orig --nx 128 --ny 128 --nz 64 --num_iter 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "srun -n 1 ./stencil2d-jparallel.x --nx 128 --ny 128 --nz 64 --num_iter 1024 > report_jparallel.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export OMP_NUM_THREADS=1\n",
    "srun -n 1 ./stencil2d-jparallel.x+orig --nx 128 --ny 128 --nz 64 --num_iter 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Number of Threads\n",
    "\n",
    "We now know that we have 12 cores availiable on the CPU. We want to investigate what the best number of threads is. While it is possible to increase the number of threads beyond the number of cores (in fact the default value we found above is 24, giving 2 threads per core), there probably is an optimum.\n",
    "\n",
    "The thread number can be set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Now it's your turn...</b><br>\n",
    "<b>14.</b> Use the <tt>stencil2d-kparallel.F90</tt> version of the code you developed above and find the optimal number of threads.<br>\n",
    "<b>15.</b> Do the same thing for the version where you have parallelized the j-loop.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# The file should still be around, but if you need to recompile, here are the steps:\n",
    "\n",
    "# For Fortran uncomment these lines\n",
    "#module load daint-gpu\n",
    "#module switch PrgEnv-gnu PrgEnv-cray\n",
    "#make VERSION=kparallel\n",
    "\n",
    "# For C++ uncomment these lines\n",
    "#module load daint-gpu\n",
    "#CC stencil2d-kparallel.cpp -fopenmp -o stencil2d-kparallel.x -O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nthreads=1\n",
    "echo \"out = [None] * 21\" > out.txt\n",
    "for nthreads in `seq 1 20` ; do\n",
    "export OMP_NUM_THREADS=$nthreads\n",
    "  ncores=$nthreads\n",
    "  if [ $nthreads -gt 24 ] ; then\n",
    "    ncores=24\n",
    "  fi\n",
    "  srun -n 1 -c $ncores ./stencil2d-jparallel.x+orig --nx 128 --ny 128 --nz 64 --num_iter 1024 | sed \"s/data =/out[$nthreads] =/g\" >> out_j.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('out_j.txt','r').read())\n",
    "labels = []\n",
    "times = []\n",
    "for i in range(len(out)):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    labels.append(i)\n",
    "    times.append(out[i][:,5].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(labels, times)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "The concepts presented up to here are key to understanding how to optimize weather and climate codes. The next set of questions should deepen your understanding of OpenMP and shared memory parallelism in general. The following exercises can be considered a bonus if the time is too short.<br>\n",
    "The questions are split into two sections: Deeper understanding of OpenMP and playing with minor optimizations in the stencil2d example. They can be solved in either order\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding OpenMP\n",
    "\n",
    "## Diagnostics of our Field\n",
    "The first task is to understand how to uses critical sections, atomics and proper variable scoping to implement a function that calculates the maximal value present in the 3d field. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Now it's your turn...</b><br>\n",
    "<b>B1.</b> Make a copy of the base source code and name it stencil2d-max.F90\n",
    "Add the function that iterates over all fields and reports the highest value found after every 100th iteration. Report the value to the standard output (<code>std::cout</code> or <code>$ write(*, *)</code>)<br>\n",
    "<b>B2.</b> Parallelize the diagnostics. Can you put this into a parallel section or does it need its own? Can you reproduce the same results?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# For Fortran uncomment these lines\n",
    "module load daint-gpu\n",
    "module switch PrgEnv-gnu PrgEnv-cray\n",
    "make VERSION=max\n",
    "\n",
    "# For C++ uncomment these lines\n",
    "#module load daint-gpu\n",
    "#CC stencil2d-max.cpp -fopenmp -o stencil2d-max.x -O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "srun -n 1 ./stencil2d-max.x --nx 128 --ny 128 --nz 64 --num_iter 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# For Fortran uncomment these lines\n",
    "module load daint-gpu\n",
    "module switch PrgEnv-gnu PrgEnv-cray\n",
    "make VERSION=max\n",
    "\n",
    "# For C++ uncomment these lines\n",
    "#module load daint-gpu\n",
    "#CC stencil2d-parallelmax.cpp -fopenmp -o stencil2d-parallelmax.x -O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "srun -n 1 ./stencil2d-parallelmax.x --nx 128 --ny 128 --nz 64 --num_iter 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Implementation of the `omp parallel for` Pragma\n",
    "There is a way to re-implement what a parallel for loop does with the directives `omp parallel`, `omp private`, `omp single`(or similar) and `omp task`. We let the scheduling happen automagically and do not worry about it for now. \n",
    "The second task is to write a simple loop that prints the threadnumber that executes the itearion as well as the iteration number though the full loop. A skeletoncode is available in forloop.cpp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Now it's your turn...</b><br>\n",
    "<b>B3.</b> Insert the required pragmas to make sure that more than one thread works on the various pieces of the code\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load daint-gpu\n",
    "\n",
    "CC forloop.cpp -fopenmp -o forloop.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "srun -n 1 ./forloop.x 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minor Optimizations of Stencil2D\n",
    "\n",
    "## Fusing the Computation Loops\n",
    "\n",
    "Currently we have the computation in two ij loops. Since we know that writing into a 2d field and reading it again might be additional memory overhead, we would ideally have the computation in just one loop.\n",
    "\n",
    "There is a way to fuse the compuatational loops (and have the update on a separate loop). \n",
    "\n",
    "The code would have the stuctuce of `stencil2d-fusion.F90 / cpp`.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Now it's your turn...</b><br>\n",
    "<b>B4.</b> Implement the loop bounds and the computation.<br>\n",
    "<b>B5.</b> Quickly check that the results are still ok (using <tt>validate_results()</tt>, see below)<br>\n",
    "<b>B6.</b> Use any combination of techniques learned to parallelize this code<br>\n",
    "<b>B7.</b> Look at the performance in your ideal setting (parallelization with either j or k loop, optimal number of threads)/ How does it compare? How much speedup would you have expected?<br>\n",
    "    <b>B8.</b> By looking at the perftools-lite report, can you explain the performance?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# For Fortran uncomment these lines\n",
    "module load daint-gpu\n",
    "module switch PrgEnv-gnu PrgEnv-cray\n",
    "module load perftools-lite\n",
    "make VERSION=fusion\n",
    "\n",
    "# For C++ uncomment these lines\n",
    "#module load daint-gpu\n",
    "#module load perftools-lite\n",
    "#CC stencil2d-fusion.cpp -fopenmp -o stencil2d-fusion.x -O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "srun -n 1 ./stencil2d-fusion.x+orig --nx 128 --ny 128 --nz 64 --num_iter 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "srun -n 1 ./stencil2d-fusion.x --nx 128 --ny 128 --nz 64 --num_iter 1024 > report_inlining.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelizing the Halo Update\n",
    "\n",
    "The halo updates are a set of small loops that are all independent. The amount of work done in there independen loops is significantly smaller than the work in the main loop. We try to investigate how to parallelize them efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Now it's your turn...</b><br>\n",
    "<b>B9.</b> By looking at the perftools report of previous runs, can you explain why this was a bonus exercise? What is the expected performance gain of this parallelization? <br>\n",
    "    <b>B10.</b> Make a copy of the source code and name it <tt>stencil2d-parallel-halo.F90</tt><br>\n",
    "<b>B11</b> Implement a paralell version of the halo updates with the learnings from before (which loop to parallelize, what number of threads to use, how to scope the variables)<br>\n",
    "<b>B12</b> Quickly check that the results are still ok (using <tt>validate_results()</tt>, see below)<br>\n",
    "<b>B13.</b> By looking at the performance report, can you discuss your predictions? Why were they / were they not matched?<br>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# For Fortran uncomment these lines\n",
    "module load daint-gpu\n",
    "module switch PrgEnv-gnu PrgEnv-cray\n",
    "module load perftools-lite\n",
    "make VERSION=parallel-halo\n",
    "\n",
    "# For C++ uncomment these lines\n",
    "#module load daint-gpu\n",
    "#module load perftools-lite\n",
    "#CC stencil2d-parallel-halo.cpp -fopenmp -o stencil2d-parallel-halo.x -O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "srun -n 1 ./stencil2d-parallel-halo.x+orig --nx 128 --ny 128 --nz 64 --num_iter 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the ideal schedule for our program\n",
    "We know that in a lot of programs, the loop schedule can have a significant impact on the performance. Since weather and climate codes are usually very nicely structured with similar work loads across iterations (excluding boundary layer computation in the vertical), finding the ideal schedule might only lead to small performance gains. We try to neverthenless understand how different schedules behave and what their performance looks like.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Now it's your turn...</b><br>\n",
    "<b>B14.</b> Modify your code stencil2d-jparallel to test these three loop orders: <br>\n",
    "<code>static(1)\n",
    "static(ny/p)\n",
    "dynamic(1)\n",
    "</code>\n",
    "   How does the performance compare? Can you explain what these schedules do?<br>\n",
    "    <b>B15.</b> What would happen if we did the same experiment on the kparallel version?<br>\n",
    "<b>B16.</b> Can you think of codes where this is more impactful? Why?\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# For Fortran uncomment these lines\n",
    "module load daint-gpu\n",
    "module switch PrgEnv-gnu PrgEnv-cray\n",
    "module load perftools-lite\n",
    "make VERSION=jparallel\n",
    "\n",
    "# For C++ uncomment these lines\n",
    "#module load daint-gpu\n",
    "#module load perftools-lite\n",
    "#CC stencil2d-jparallel.cpp -fopenmp -o stencil2d-jparallel.x -O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "srun -n 1 ./stencil2d-jparallel.x+orig --nx 128 --ny 128 --nz 64 --num_iter 1024"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full_hpc4wc",
   "language": "python",
   "name": "full_hpc4wc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
