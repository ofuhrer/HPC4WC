{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99779fba",
   "metadata": {},
   "source": [
    "### Notebook 3: Analyze Benchmarks and Create Plots\n",
    "\n",
    "This is the third and final notebook in the sequence. At this point, all the results have been calculated and the three implementations have been verified. Now we will create the plots for the final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d74b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('notebook_03: started.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad3e81",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26009055",
   "metadata": {},
   "source": [
    "#### Helper Functions\n",
    "\n",
    "First, we will define some useful helper functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9df78c",
   "metadata": {},
   "source": [
    "This function reads the benchmark files created by the first notebook. These files are plain text and the data is formatted as a `pandas.DataFrame`. This means that we can simply evaluate the text file as Python code and get a `DataFrame` as a result. The three implementations all write their output in the same format, so this function will work for all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7762abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_benchmark_file(filename) -> pd.DataFrame:\n",
    "    with open(filename, mode='r', encoding='utf-8') as file:\n",
    "        contents = file.read()\n",
    "    return eval(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7d72d",
   "metadata": {},
   "source": [
    "This function calculates the number of grid points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d881e2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_gridsize(bench):\n",
    "    gridsize = bench['x'] * bench['y'] * bench['z']\n",
    "    return gridsize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659732d6",
   "metadata": {},
   "source": [
    "This function calculates the runtime per grid point. Note that the time column of the `DataFrame` contains the runtime in milliseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13279872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_runtime_per_gridpoint(bench):\n",
    "    rt_ms = bench['time'] / (bench['x'] * bench['y'] * bench['z'])\n",
    "    rt_us = 1e3 * rt_ms\n",
    "    return rt_us"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e14664",
   "metadata": {},
   "source": [
    "This function calculates the size of the working set in memory in megabytes. We need to specify the memory size of a numeric value. If the code uses `float` as numeric precision, we have 4 bytes per value. If the numerical precision is `double`, we have 8 bytes per value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09407d20",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_workingset(bench, bytes_per_value, num_fields):\n",
    "    gs_B = num_fields * bytes_per_value * bench['x'] * bench['y'] * bench['z']\n",
    "    gs_MiB = gs_B / 1024 / 1024\n",
    "    return gs_MiB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371ae566",
   "metadata": {},
   "source": [
    "This function adds all the derived measures that we need for the plots to the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c415619c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def add_derived_measures(bench):\n",
    "    bench['rt_per_gp'] = get_runtime_per_gridpoint(bench)\n",
    "    bench['gridsize'] = get_gridsize(bench)\n",
    "    bench['workingset'] = get_workingset(bench, bytes_per_value=4, num_fields=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d65135",
   "metadata": {},
   "source": [
    "The following functions are used to remove specific data points from a benchmark. We may want to do this if we are not interested in certain ranges of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e98a51a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def remove_values(bench, mask):\n",
    "    result = bench.loc[~mask, :]\n",
    "    result.reset_index(drop=True, inplace=True)\n",
    "    return result\n",
    "\n",
    "def remove_values_or(bench, x, y):\n",
    "    mask = (bench['x'] == x) | (bench['y'] == y)\n",
    "    return remove_values(bench, mask)\n",
    "\n",
    "def remove_values_and(bench, x, y):\n",
    "    mask = (bench['x'] == x) & (bench['y'] == y)\n",
    "    return remove_values(bench, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4e240",
   "metadata": {},
   "source": [
    "#### Read Benchmark Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b0933",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('notebook_03: reading benchmark files ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832d4c50",
   "metadata": {},
   "source": [
    "Now we read the the benchmark files created by the Fortran and C++/CUDA executables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7f3f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_oacc = read_benchmark_file('./data/bench_openacc.txt')\n",
    "bench_cuda_direct08 = read_benchmark_file('./data/bench_cuda_noshared08.txt')\n",
    "bench_cuda_direct16 = read_benchmark_file('./data/bench_cuda_noshared16.txt')\n",
    "bench_cuda_direct32 = read_benchmark_file('./data/bench_cuda_noshared32.txt')\n",
    "bench_cuda_shared04 = read_benchmark_file('./data/bench_cuda_shared04.txt')\n",
    "bench_cuda_shared12 = read_benchmark_file('./data/bench_cuda_shared12.txt')\n",
    "bench_cuda_shared28 = read_benchmark_file('./data/bench_cuda_shared28.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf6f521",
   "metadata": {},
   "source": [
    "For each implementation, we calculate the required values for the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bb9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_derived_measures(bench_oacc)\n",
    "add_derived_measures(bench_cuda_direct08)\n",
    "add_derived_measures(bench_cuda_direct16)\n",
    "add_derived_measures(bench_cuda_direct32)\n",
    "add_derived_measures(bench_cuda_shared04)\n",
    "add_derived_measures(bench_cuda_shared12)\n",
    "add_derived_measures(bench_cuda_shared28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bc09a0",
   "metadata": {},
   "source": [
    "#### Create Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57170019",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('notebook_03: creating plots ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf5d433",
   "metadata": {},
   "source": [
    "\n",
    "We remove some data points for very small grid sizes from the benchmarks so that the plot focuses on the relevant range of grid sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb88ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_oacc = remove_values_and(bench_oacc, x=16, y=16)\n",
    "bench_cuda_direct08 = remove_values_or(bench_cuda_direct08, x=12, y=12)\n",
    "bench_cuda_direct16 = remove_values_or(bench_cuda_direct16, x=12, y=12)\n",
    "bench_cuda_shared04 = remove_values_or(bench_cuda_shared04, x=12, y=12)\n",
    "bench_cuda_shared12 = remove_values_or(bench_cuda_shared12, x=12, y=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2121b9",
   "metadata": {},
   "source": [
    "In this first plot, we show the relationship between working set size and runtime per grid point. Specifically, we compare the Fortran implementation and the two C++/CUDA implementations with and without shared memory usage. For the CUDA implementation, we choose the block size that is most useful for practical applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325a2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.loglog(bench_oacc['workingset'], bench_oacc['rt_per_gp'], '.', label='OpenACC')\n",
    "ax.loglog(bench_cuda_direct16['workingset'], bench_cuda_direct16['rt_per_gp'], '.', label='CUDA Direct16')\n",
    "ax.loglog(bench_cuda_shared12['workingset'], bench_cuda_shared12['rt_per_gp'], '.', label='CUDA Shared12')\n",
    "ax.axvline(4, color='purple', label='L2 Chache Size')\n",
    "ax.grid(which='major', linestyle='-')\n",
    "ax.grid(which='minor', linestyle=':')\n",
    "ax.set_xlabel('Size of working set [MiB]')\n",
    "ax.set_ylabel('Runtime per gridpoint [µs]')\n",
    "ax.set_title('Runtime vs. Working Set Size')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig.savefig('./data/plot_runtime_mix.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a796d6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "In the next plot, we compare how block size affects performance for a CUDA implementation with no shared memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd98ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.loglog(bench_cuda_direct08['workingset'], bench_cuda_direct08['rt_per_gp'], '.', label='CUDA Direct08')\n",
    "ax.loglog(bench_cuda_direct16['workingset'], bench_cuda_direct16['rt_per_gp'], '.', label='CUDA Direct16')\n",
    "ax.loglog(bench_cuda_direct32['workingset'], bench_cuda_direct32['rt_per_gp'], '.', label='CUDA Direct32')\n",
    "ax.axvline(4, color='purple', label='L2 Chache Size')\n",
    "ax.grid(which='major', linestyle='-')\n",
    "ax.grid(which='minor', linestyle=':')\n",
    "ax.set_xlabel('Size of working set [MiB]')\n",
    "ax.set_ylabel('Runtime per gridpoint [µs]')\n",
    "ax.set_title('Runtime vs. Working Set Size')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig.savefig('./data/plot_runtime_direct.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed91ca1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "In this last plot, we again compare different block sizes. This time we are looking at the shared memory CUDA implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b25b7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.loglog(bench_cuda_shared04['workingset'], bench_cuda_shared04['rt_per_gp'], '.', label='CUDA Shared04')\n",
    "ax.loglog(bench_cuda_shared12['workingset'], bench_cuda_shared12['rt_per_gp'], '.', label='CUDA Shared12')\n",
    "ax.loglog(bench_cuda_shared28['workingset'], bench_cuda_shared28['rt_per_gp'], '.', label='CUDA Shared28')\n",
    "ax.axvline(4, color='purple', label='L2 Chache Size')\n",
    "ax.grid(which='major', linestyle='-')\n",
    "ax.grid(which='minor', linestyle=':')\n",
    "ax.set_xlabel('Size of working set [MiB]')\n",
    "ax.set_ylabel('Runtime per gridpoint [µs]')\n",
    "ax.set_title('Runtime vs. Working Set Size')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig.savefig('./data/plot_runtime_shared.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "comment_magics": false
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
